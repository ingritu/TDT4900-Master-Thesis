<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.18"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>TDT4900-Master-Thesis: TDT4900-Master-Thesis</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TDT4900-Master-Thesis
   &#160;<span id="projectnumber">1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.18 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">TDT4900-Master-Thesis </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Image Captioning</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Installations</h1>
<p>First go to <a href="https://github.com/salaniz/pycocoevalcap">https://github.com/salaniz/pycocoevalcap</a> to install pycocoevalcap and pycocotools. We need these packages to evaluate the model, and this is copatible with python 3.</p>
<p>It is possible that you will get an error saying "No module named Cython" while you are trying to install the packages. If you get this error just install Cython by entering this into the terminal:</p>
<div class="fragment"><div class="line">pip install cython</div>
</div><!-- fragment --><p>Once cython is installed you should be able to install pycocoevalcap and pycocotools.</p>
<p>Then install the rest of the requirements by running: </p><div class="fragment"><div class="line">pip install -r requirements.txt</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md2"></a>
Running project</h1>
<h2><a class="anchor" id="autotoc_md3"></a>
1. Make the dataset</h2>
<div class="fragment"><div class="line">python3 -m src.data.make_dataset --help</div>
<div class="line"> </div>
<div class="line">usage: src.data.make_dataset.py [-h] [--dataset DATASET] [--karpathy KARPATHY]</div>
<div class="line"> </div>
<div class="line">optional arguments:</div>
<div class="line">  -h, --help           show this help message and exit</div>
<div class="line">  --dataset DATASET    Dataset to train on. The options are {flickr8k,</div>
<div class="line">                       flickr30k, coco}.</div>
<div class="line">  --karpathy KARPATHY  Boolean used to decide whether to train on the karpathy</div>
<div class="line">                       split of dataset or not.</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md4"></a>
2. Make the features</h2>
<div class="fragment"><div class="line">python3 -m src.features.build_features --help</div>
<div class="line"> </div>
<div class="line">usage: src.features.build_features.py [-h] [--resize_images RESIZE_IMAGES]</div>
<div class="line">                                      [--new_image_size NEW_IMAGE_SIZE [NEW_IMAGE_SIZE ...]]</div>
<div class="line">                                      [--dataset DATASET] [--visual_attention VISUAL_ATTENTION]</div>
<div class="line">                                      [--output_layer_idx OUTPUT_LAYER_IDX]</div>
<div class="line"> </div>
<div class="line">optional arguments:</div>
<div class="line">  -h, --help            show this help message and exit</div>
<div class="line">  --resize_images RESIZE_IMAGES</div>
<div class="line">                        Boolean to decide whether to resize the images before</div>
<div class="line">                        building the actual features.</div>
<div class="line">  --new_image_size NEW_IMAGE_SIZE [NEW_IMAGE_SIZE ...]</div>
<div class="line">                        List new image dimensions. should be something like</div>
<div class="line">                        299 299.</div>
<div class="line">  --dataset DATASET     Which dataset to create image features for. The</div>
<div class="line">                        options are {flickr8k, flickr30k, coco}.</div>
<div class="line">  --visual_attention VISUAL_ATTENTION</div>
<div class="line">                        Boolean for deciding whether to extract visual</div>
<div class="line">                        features that are usable for models that use visualt</div>
<div class="line">                        attention.</div>
<div class="line">  --output_layer_idx OUTPUT_LAYER_IDX</div>
<div class="line">                        Which layer to extract features from.</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md5"></a>
3. Train a model</h2>
<div class="fragment"><div class="line">python3 -m src.models.train_model --help</div>
<div class="line"> </div>
<div class="line">usage: src.models.train_model.py [-h] [--batch_size BATCH_SIZE]</div>
<div class="line">                                 [--val_batch_size VAL_BATCH_SIZE] [--beam_size BEAM_SIZE]</div>
<div class="line">                                 [--epochs EPOCHS] [--embedding_size EMBEDDING_SIZE]</div>
<div class="line">                                 [--hidden_size HIDDEN_SIZE] [--loss_function LOSS_FUNCTION]</div>
<div class="line">                                 [--optimizer OPTIMIZER] [--lr LR] [--seed SEED] [--model MODEL]</div>
<div class="line">                                 [--karpathy KARPATHY] [--dataset DATASET] --image_feature_size</div>
<div class="line">                                 IMAGE_FEATURE_SIZE [IMAGE_FEATURE_SIZE ...]</div>
<div class="line"> </div>
<div class="line">optional arguments:</div>
<div class="line">  -h, --help            show this help message and exit</div>
<div class="line">  --batch_size BATCH_SIZE</div>
<div class="line">                        Training batch size. The number of captions in a</div>
<div class="line">                        batch.</div>
<div class="line">  --val_batch_size VAL_BATCH_SIZE</div>
<div class="line">                        Validation batch size. The number of images in a</div>
<div class="line">                        batch. The actual batch size is val_batch_size *</div>
<div class="line">                        beam_size.</div>
<div class="line">  --beam_size BEAM_SIZE</div>
<div class="line">                        Beam size to use in beam search inference algorithm.</div>
<div class="line">                        Bigger beam size yields higher performance.</div>
<div class="line">  --epochs EPOCHS       The number of epochs to train the network for.</div>
<div class="line">  --embedding_size EMBEDDING_SIZE</div>
<div class="line">                        Embedding dimension. The size of the word vector</div>
<div class="line">                        representations.</div>
<div class="line">  --hidden_size HIDDEN_SIZE</div>
<div class="line">                        Hidden dimension.</div>
<div class="line">  --loss_function LOSS_FUNCTION</div>
<div class="line">                        Loss/Cost function to use during training.</div>
<div class="line">  --optimizer OPTIMIZER</div>
<div class="line">                        Optimizer to use during training.</div>
<div class="line">  --lr LR               Initial learning rate for the decoder.</div>
<div class="line">  --seed SEED           Random state seed.</div>
<div class="line">  --model MODEL         Model name. Which model type to train.</div>
<div class="line">  --karpathy KARPATHY   Boolean used to decide whether to train on the</div>
<div class="line">                        karpathy split of dataset or not.</div>
<div class="line">  --dataset DATASET     Dataset to train on. The options are {flickr8k,</div>
<div class="line">                        flickr30k, coco}.</div>
<div class="line">  --image_feature_size IMAGE_FEATURE_SIZE [IMAGE_FEATURE_SIZE ...]</div>
<div class="line">                        List integers. Should be something like</div>
<div class="line">                        --image_feature_size 8 8 1536.</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md6"></a>
4. Evaluate a trained model</h2>
<div class="fragment"><div class="line">python3 -m src.models.predict_model --help</div>
<div class="line"> </div>
<div class="line">usage: src.models.predict_model.py [-h] [--karpathy KARPATHY] [--dataset DATASET] [--split SPLIT]</div>
<div class="line">                                   [--model_name MODEL_NAME] --model MODEL</div>
<div class="line">                                   [--val_batch_size VAL_BATCH_SIZE] [--beam_size BEAM_SIZE]</div>
<div class="line"> </div>
<div class="line">optional arguments:</div>
<div class="line">  -h, --help            show this help message and exit</div>
<div class="line">  --karpathy KARPATHY   Boolean used to decide whether to train on the</div>
<div class="line">                        karpathy split of dataset or not.</div>
<div class="line">  --dataset DATASET     Dataset to test model on. The options are {flickr8k,</div>
<div class="line">                        flickr30k, coco}.</div>
<div class="line">  --split SPLIT         Dataset split to evaluate. Acceptable values are</div>
<div class="line">                        {train, val, test}.</div>
<div class="line">  --model_name MODEL_NAME</div>
<div class="line">                        Model type.</div>
<div class="line">  --model MODEL         Name of the models directory. Should be something like</div>
<div class="line">                        adaptive_decoder_dd-Mon-yyyy_(hh:mm:ss).</div>
<div class="line">  --val_batch_size VAL_BATCH_SIZE</div>
<div class="line">                        Validation batch size. The number of images in a</div>
<div class="line">                        batch. The actual batch size is val_batch_size *</div>
<div class="line">                        beam_size.</div>
<div class="line">  --beam_size BEAM_SIZE</div>
<div class="line">                        Beam size to use in beam search inference algorithm.</div>
<div class="line">                        Bigger beam size yields higher performance.</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md7"></a>
Project Structure</h1>
<div class="fragment"><div class="line">/</div>
<div class="line">├── data/</div>
<div class="line">│   ├── raw/</div>
<div class="line">│   │   ├── Flick8k/</div>
<div class="line">│   │   ├── Flickr30k/</div>
<div class="line">│   │   ├── karpathy_split/</div>
<div class="line">│   │   │   ├── datase_coco.json</div>
<div class="line">│   │   │   ├── datase_flickr8k.json</div>
<div class="line">│   │   │   └── datase_flickr30k.json</div>
<div class="line">│   │   └── MSCOCO/</div>
<div class="line">│   │       ├── annotations/</div>
<div class="line">│   │       ├── test2014/</div>
<div class="line">│   │       ├── train2014/</div>
<div class="line">│   │       └── val2014/</div>
<div class="line">│   ├── interim/</div>
<div class="line">│   ├── processed/</div>
<div class="line">│   └── README.md</div>
<div class="line">├── docs/</div>
<div class="line">│   └── README.md</div>
<div class="line">├── models/</div>
<div class="line">│   └── README.md</div>
<div class="line">├── notebooks/</div>
<div class="line">│   ├── annotation_file_exploration.ipynb</div>
<div class="line">│   ├── karpathy_split_exploration.ipynb</div>
<div class="line">│   ├── README.md</div>
<div class="line">│   ├── visualize_word_frequency.ipynb</div>
<div class="line">│   └── visuals/</div>
<div class="line">├── README.md</div>
<div class="line">├── references/</div>
<div class="line">│   ├── annotation_mock.json</div>
<div class="line">│   ├── karpathy_dataset_mock.json</div>
<div class="line">│   ├── logs_and_checkpoints.txt</div>
<div class="line">│   ├── README.md</div>
<div class="line">│   └── run_notes.txt</div>
<div class="line">├── reports/</div>
<div class="line">│   └── README.md</div>
<div class="line">├── requirements.txt</div>
<div class="line">└── src/</div>
<div class="line">    ├── data/</div>
<div class="line">    │   ├── data_cleaning.py</div>
<div class="line">    │   ├── data_generator.py</div>
<div class="line">    │   ├── handle_karpathy_split.py</div>
<div class="line">    │   ├── load_vocabulary.py</div>
<div class="line">    │   ├── make_dataset.py</div>
<div class="line">    │   ├── split_flickr8k.py</div>
<div class="line">    │   ├── subset_splits.py</div>
<div class="line">    │   ├── text_to_csv.py</div>
<div class="line">    │   └── utils.py</div>
<div class="line">    ├── features/</div>
<div class="line">    │   ├── build_features.py</div>
<div class="line">    │   ├── glove_embeddings.py</div>
<div class="line">    │   ├── resize_images.py</div>
<div class="line">    │   └── Resnet_features.py</div>
<div class="line">    ├── __init__.py</div>
<div class="line">    ├── models/</div>
<div class="line">    │   ├── beam.py</div>
<div class="line">    │   ├── custom_layers.py</div>
<div class="line">    │   ├── generator_framework.py</div>
<div class="line">    │   ├── predict_model.py</div>
<div class="line">    │   ├── torch_generators.py</div>
<div class="line">    │   ├── train_model.py</div>
<div class="line">    │   └── utils.py</div>
<div class="line">    └── visualization/</div>
<div class="line">        └── visualize.py</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.18
</small></address>
</body>
</html>
